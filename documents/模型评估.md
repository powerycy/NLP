# 模型评估

## 混淆矩阵
混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。每一列中的数值表示真实数据被预测为该类的数目：如下图，第一行第一列中的43表示有43个实际归属第一类的实例被预测为第一类，同理，第一行第二列的2表示有2个实际归属为第一类的实例被错误预测为第二类。
### 举例
如有150个样本数据，预测为1,2,3类各为50个。分类结束后得到的混淆矩阵为：
<table>
   <tr>
      <td colspan="2" rowspan="2"></td>
      <td colspan="3" align="center">预测</td>
   </tr>
   <tr>
      <td>类1</td>
      <td>类2</td>
      <td>类3</td>
   </tr>
   <tr>
      <td rowspan="3">实际</td>
      <td>类1</td>
      <td>43</td>
      <td>2</td>
      <td>0</td>
   </tr>
   <tr>
      <td>类2</td>
      <td>5</td>
      <td>45</td>
      <td>1</td>
   </tr>
   <tr>
      <td>类3</td>
      <td>2</td>
      <td>3</td>
      <td>49</td>
   </tr>
</table>

每一行之和表示该类别的真实样本数量，每一列之和表示被预测为该类别的样本数量，
第一行说明有43个属于第一类的样本被正确预测为了第一类，有两个属于第一类的样本被错误预测为了第二类。

## 二元分类器的混淆矩阵

<table>
   <tr>
      <td colspan="2" rowspan="2"></td>
      <td colspan="3" align="center">预测值</td>
   </tr>
   <tr>
      <td>正例</td>
      <td>负例</td>
   </tr>
   <tr>
      <td rowspan="2">实际值</td>
      <td>正例</td>
      <td>真正例（TP）</td>
      <td>假负例（FN）</td>
   </tr>
   <tr>
      <td>负例</td>
      <td>假正例（FP）</td>
      <td>真负例（TN）</td>
   </tr>
</table>

### 精确率（Precision)
$$P = \frac{TP}{TP + FP}$$
### 召回率（Recall)
$$R = \frac{TP}{TP + FN}$$
### 特异性（specificity)
$$S = \frac{TN}{FP + TN }$$
### F1（F1 measure）
有时也用一个$F_1$值来综合评估精确率和召回率，它是精确率和召回率的调和均值。当精确率和召回率都高时，$F_1$值也会高。严格的数学定义如下：

$$\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}$$

即：

$$F_1 = 2\frac{PR}{P+R} $$


有时候我们对精确率和召回率并不是一视同仁，比如有时候我们更加重视精确率。我们用一个参数$\beta$来度量两者之间的关系。如果$\beta>1$, 召回率有更大影响，如果$\beta<1$,精确率有更大影响。自然，当$\beta=1$的时候，精确率和召回率影响力相同，和$F_1$形式一样。含有度量参数$\beta$的$F_1$我们记为$F_\beta$, 严格的数学定义如下：

$$ F_\beta = (1+\beta^2)\frac{P*R}{\beta^2*P + R}$$

即：

$$E_\alpha = 1 - \frac{1}{\frac{\alpha}{P}+\frac{1-\alpha}{R}}$$

$$ F_\beta = 1- E_\alpha$$ 

$$ \alpha = \frac{1}{1+\beta^2}$$

可推导公式

$$ \frac{1}{F_\beta} = \frac{\alpha}{P}+\frac{1-\alpha}{R} $$

得到

$$ F_\beta = (1+\beta^2)\frac{P*R}{\beta^2*P + R}$$

### 灵敏度（true positive rate, TPR）
$$TPR=\frac{TP}{TP+FN}$$
### 1-特异度（false positive rate, FPR）
$$FPR=\frac{FP}{FP+TN}$$

## ROC（Receiver Operating Characteristic Curve）曲线

ROC中文名为“受试者工作特征曲线”。ROC曲线源于军事领域，而后在医学领域应用甚广，“受试者工作特征曲线”这一名称也正是来自于医学领域。指在特定刺激条件下，以被试在不同判断标准下所得的虚报概率FPR为横坐标，以击中概率TPR为纵坐标，画得的各点的连线。又称为感受性曲线（sensitivity curve）。得此名的原因在于曲线上各点反映着相同的感受性，它们都是对同一信号刺激的反应，只不过是在几种不同的判定标准下所得的结果而已。接受者操作特性曲线就是以虚惊概率为横轴，击中概率为纵轴所组成的坐标图，和被试在特定刺激条件下由于采用不同的判断标准得出的不同结果画出的曲线

ROC曲线就反映了 FPR 与 TPR 之间权衡的情况，通俗地来说，即在TPR随着FPR递增的情况下，谁增长得更快，快多少的问题。TPR增长得越快，曲线越往上屈，AUC就越大，反映了模型的分类性能就越好。当正负样本不平衡时，这种模型评价方式比起 一般的精确度评价方式的好处尤其显著。

![roc](/assets/images/模型评估/roc.png)

有一种直观地绘制 ROC 曲线的方法。 首先，根据样本标签统计出正负样本的数量，假设正样本数量为 P，负样本数量为 N; 接下来，把横轴的刻度间隔设置为 1/N， 纵轴的刻度间隔设置为 1/P; 再根据模型输出的预测概率对样本进行排序(从高到低) ;依次遍历样本，同时从零点开始绘制 ROC 曲线，每遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线，每遇到一个负样本就沿横轴方向绘制一个刻度间隔的曲线，直到遍历完所有样本，曲线最终停在(1,1)这个点，整个 ROC 曲线绘制完成。

![roc](/assets/images/模型评估/roc2.png)

## AUC（Area Under Curve）

AUC(Area Under Curve)被定义为ROC曲线下的面积。 计算 AUC 值只需要沿着 ROC 横轴做积分就可以了 。显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方(如果不是的话，只要把模型预测的概率反转成 1-p就可以得到一个更好的分类器)，所以AUC的取值范围在0.5-1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而AUC作为数值可以直观的量化评价分类器的好坏，值越大越好。
AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。
0.5 < AUC < 1，优于随机猜测。这个分类器(模型)妥善设定阈值的话，能有预测价值。
AUC = 0.5，跟随机猜测一样(例:丢铜板)，模型没有预测价值。 AUC < 0.5，比随机猜测还差;但只要总是反预测而行，就优于随机猜测。

## P-R 曲线

在有些模型中，我们需要对精确率与召回率进行权衡，比如视频模糊搜索功能，搜索排序模型返回的Top5的精确率非常高，但实际使用过程中，用户经常找不到想要的视频，特别是一些比较冷门的剧集。

在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用 Top N 返回结果的 Precision 值和 Recall 值来衡量排序模型的性能，即认为模型返回的 Top N 的结果就是模型 判定的正样本 ， 然后计算前 N 个位置上的准确率 Precision@N 和前 N 个位置上的召回率 Recall@N。

Precision 值和 Recall 值是既矛盾又统一的两个指标，为了提高Precision 值，分类器需要尽量在“更高把握”时才把样本预测为正样 本，但此时往往会因为过于保守而漏掉很多“没有把握”的正样本，导致 Recall 值降低 。

为了更全面地反应模型在Precision值和Recall值两方面的表现，综合评估一个排序模型的好坏，我们不仅要看模型在不同 Top N 下的 Precision@N 和 Recall@N，而且最好绘制出模型的 P-R(Precision-Recall )曲线。这里简单介绍一下 P-R 曲线的绘制方法。

P-R 由线的横轴是召回率，纵轴是精确率。对于一个排序模型来说， 其 P-R 曲线上的一个点代表着，在某一阈值下 ，模型将大于该阈值的结果判定为正样本，小于该阈值的结果判定为负样本，此时返回结果对应的召回率和精确率。 整条 P-R 由线是通过将阈值从高到低移动而生成的。


![P-R曲线](/assets/images/模型评估/P-R曲线.png)

 由图可见，当召回率接近于0时，模型A的精确率为 0.9，模型B的精确率是1，这说明模型B得分前几位的样本全部是真正的正样本，而模型A即使得分最高的几个样本也存在预测错误的情况。 并且，随着召回率的增加，精确率整体呈下降趋势。但是，当召回率为1时，模型 A 的精确率反而超过了模型B。 这充分说明，只用某个点对应的精确率和召回率是不能全面地衡量模型的性能，只有通过 P-R 曲线的整体表现，才能够对模型进行更为全面的评估 。

 ## ROC曲线相比P-R曲线有什么特点？

 相比P-R曲线，ROC曲线有一个特点，当正负样本的分布发生变化时，ROC曲线的形状能够基本保持不变，而P-R曲线的形状一般会发生较剧烈的变化。

 举例：

 ![ROC曲线和P-R曲线对比图](/assets/images/模型评估/ROC曲线和P-R曲线对比图.png)

 由图可以看出，在负样本数量增加10倍后，P-R曲线发生了明显的变化，而ROC曲线形状基本不变 。 这个特点让ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。这有什么实际意义呢?在很多实际问题中，正负样本数量往往很不均衡。比如，计算广告领域经常涉及转化率模型，正样本的数量往往是负样本数量的1/1000 甚至1/10000。 若选择不同的测试集，P-R 曲线的变化就会非常大，而ROC由线则能够更加稳定地反映模型本身的好坏。所以，ROC曲线的适用场景更多，被广泛用于排序、推荐、广告等领域。但需要注意的是，选择P-R曲线还是ROC曲线是因实际问题而异的，如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。

ROC曲线的优点是不会随着类别分布的改变而改变，但这在某种程度上也是其缺点。因为负例N增加了很多，而曲线却没变，这等于产生了大量FP。像信息检索中如果主要关心正例的预测准确性的话，这就不可接受了。

在类别不平衡的背景下，负例的数目众多致使FPR的增长不明显，导致ROC曲线呈现一个过分乐观的效果估计。ROC曲线的横轴采用FPR，根据$FPR=\frac{FP}{N}=\frac{FP}{FP+TN}$当负例N的数量远超正例P时，FP的大幅增长只能换来FPR的微小改变。结果是虽然大量负例被错判成正例，在ROC曲线上却无法直观地看出来。（当然也可以只分析ROC曲线左边一小段）
举个例子，假设一个数据集有正例20，负例10000，开始时有20个负例被错判，$FPR=\frac{20}{20+9980}=0.002$，接着又有20个负例错判，$FPR_2=\frac{40}{40+9960}=0.004$，在ROC曲线上这个变化是很细微的。而与此同时Precision则从原来的0.5下降到了0.33，在PR曲线上将会是一个大幅下降。

## ROC 曲线和 P-R 曲线使用场景
1. ROC曲线由于兼顾正例与负例，所以适用于评估分类器的整体性能，相比而言PR曲线完全聚焦于正例。

2. 如果有多份数据且存在不同的类别分布，比如信用卡欺诈问题中每个月正例和负例的比例可能都不相同，这时候如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合，因为类别分布改变可能使得PR曲线发生变化时好时坏，这种时候难以进行模型比较；反之，如果想测试不同类别分布下对分类器的性能的影响，则PR曲线比较适合。

3. 如果想要评估在相同的类别分布下正例的预测情况，则宜选PR曲线。

4. 类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好。

5. 最后可以根据具体的应用，在曲线上找到最优的点，得到相对应的precision，recall，f1 score等指标，去调整模型的阈值，从而得到一个符合具体应用的模型。


---
**参考**：  
1. [Confusion Matrix](http://www2.cs.uregina.ca/~dbd/cs831/notes/confusion_matrix/confusion_matrix.html)
2. 维基百科：[Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall)
3. 刘建平博客：[精确率与召回率，RoC曲线与PR曲线](https://www.cnblogs.com/pinard/p/5993450.html)
4. 百度百科：[混淆矩阵](https://baike.baidu.com/item/混淆矩阵)
5. 百度百科：[接受者操作特征曲线](https://baike.baidu.com/item/接受者操作特征曲线)
6. 诸葛越《百面机器学习——算法工程师带你去面试》
7. [机器学习之类别不平衡问题 (2) —— ROC和PR曲线](https://www.cnblogs.com/massquantity/p/8592091.html)
