# 负采样算法

在基于 Negative Sampling的CBOW和 Skip-graIm模型中，负采样是个很重要的环节，对于一个给定的词$w$，如何生成$NEG(w)$呢?

词典$\mathcal{D}$中的词在语料$\mathcal{C}$中出现的次数有高有低，对于那些高频词，被选为负样本的概率就应该比较大，反之，对于那些低频词，其被选中的概率就应该比较小。这就是我们对采样过程的一个大致要求，本质上就是一个带权采样问题。

下面先用一段通俗的描述来帮助读者理解带权采样的机理。

设词典$\mathcal{D}$中的每一个词$w$对应一个线段$l(w)$，长度为

$$
len(w) = \frac{counter(w)}{\sum_{u\in \mathcal{D}} counter(u)}
$$

这里 $counter(\cdot)$表示一个词在语料$\mathcal{C}$中出现的次数(分母中的求和项用来做归一化)。现在将这些线段首尾相连地拼接在一起形成一个长度为1的单位线段。如果随机地往这个单位线段上打点，则其中长度越长的线段(对应高频词)被打中的概率就越大。

接下来再谈谈word2vec中的具体做法。记$l_0=0,l_k=\sum_{j=1}^k len(w_j),k=1,2,\cdots,N$,这里$w_j$表示词典$\mathcal{D}$中第$j$个词，则以$\{l_j\}_{j=0}^N$为剖分节点可得到区间$[0,1]$上的一个**非等距剖分**,$I_i=(l_{i-1},l_i],i=1,2,\cdots,N$为其$N$个剖分区间。进一步引入区间[0,1]上的一个等距离剖分，剖分节点为$\{m_j\}_{j=0}^M$，其中$M\gg N$，具体见下图：


![等距与非等距剖分映射图](/assets/images/负采样/等距与非等距剖分映射图.png)
<center>等距与非等距剖分映射图</center>

将内部剖分节点$\{m_j\}_{j=1}^{M-1}$ 投影到非等距剖分上，如上图中红色虚线所示，则可建立$\{m_j\}_{j=1}^{M-1}$ 与区间$\{ I_j\}_{j=1}^N$(或者说$\{ w_j\}_{j=1}^N$)的映射关系：

$$Table(i)=w_k, where m_i \in I_k,i=1,2,\cdots,M-1.$$

有了这个映射，采样就简单了：每次生成一个$[1,M-1]$间的随机整数$r$,$Table(r)$就是一个样本。这里还有一个细节，当对$w_i$进行负采样时，如果碰巧选到$w_i$自己怎么办？那就跳过去呗，代码中也是这么处理的。

值得一提的是，word2vec 源码中为词典$\mathcal{D}$中的词设置权值时，不是直接用$counter(w)$，而是对其做了$\alpha$次幂，其中$\alpha=\frac{3}{4}$，即：

$$
len(w)=\frac{[counter(w)]^\frac{3}{4}}{\sum_{u\in \mathcal{D}}[counter(u)]^\frac{3}{4}}
$$

此外，代码中取$M=10^8$（对应源码中变量[table_size](https://github.com/tmikolov/word2vec/blob/master/word2vec.c)）映射$Table(i)$则通过一个名为 [InitUnigramTable](https://github.com/tmikolov/word2vec/blob/master/word2vec.c) 的函数来完成的。


---
**参考**： 
* [word2vec 中的数学原理详解（二）预备知识](https://blog.csdn.net/itplus/article/details/37969635)
